\documentclass[sigconf,review,anonymous]{acmart}

%% Packages
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{algorithm}
\usepackage{algpseudocode}

%% Algorithm commands
\algnewcommand\algorithmicparfor{\textbf{parallel for}}
\algdef{S}[FOR]{ParFor}[1]{\algorithmicparfor\ #1\ \algorithmicdo}

%% Code listing style
\lstset{
  basicstyle=\small\ttfamily,
  keywordstyle=\color{blue},
  commentstyle=\color{gray},
  numbers=left,
  numberstyle=\tiny,
  breaklines=true,
  frame=single
}

%% BibTeX command
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

\begin{document}

%%
%% Title
%%
\title{Sawtooth Access Pattern: Reducing L2 Cache Misses in Fused Multi-Head Attention via Alternating Traversal}

\renewcommand{\shortauthors}{Anonymous, et al.}

%%
%% Abstract
%%
\begin{abstract}
Fused Multi-Head Attention (FMHA) kernels are critical to transformer performance, yet their streaming access patterns lead to significant L2 cache thrashing. Through detailed empirical analysis, we show that L2 behavior in FMHA is deterministic and modelable, but capacity misses emerge at sequence lengths well below theoretical limits. We present the \textbf{sawtooth access pattern}, a technique that alternates the traversal direction of key-value (KV) tiles across adjacent query blocks to maximize temporal locality in L2 cache. We implement this optimization in both CuTile and Triton frameworks and propose a compiler pass (\texttt{AlternateReductionLoopPass}) for CuTile IR that automatically transforms reduction loops. Our experiments on NVIDIA GB10 (Blackwell) demonstrate that the sawtooth pattern reduces L2 non-compulsory misses by up to 3--6$\times$ and improves throughput by up to 1.6$\times$ across causal and non-causal attention variants, with consistent benefits for both FP16 and FP8 quantized workloads.
\end{abstract}

\keywords{GPU cache, attention mechanism, Flash Attention, L2 optimization, sawtooth pattern, memory access patterns, tensor cores}

\maketitle

%% ============================================================================
%% SECTION 1: INTRODUCTION
%% ============================================================================
\section{Introduction}
\label{sec:introduction}

The attention mechanism lies at the heart of transformer-based models~\cite{AttentionIsAllYouNeed, GPT3}, with fused multi-head attention (FMHA) implementations being essential for practical deployment. Flash Attention~\cite{FlashAttention} and its successors have established IO-aware tiled computation as the standard approach, reducing memory transfers between GPU HBM and on-chip SRAM. However, even optimized implementations exhibit a fundamental limitation: the \textbf{streaming access pattern} over key-value (KV) tiles leads to poor L2 cache utilization.

In a typical FMHA kernel using persistent CTAs, each CTA processes multiple query tiles sequentially. For each query tile, the CTA streams through all KV tiles in forward order. When transitioning from one query tile to the next, the KV tiles just accessed are still warm in L2---but the next query tile starts again from the beginning, wasting this cached data.

\paragraph{Key Insight.} If consecutive query tiles within a CTA traverse KV tiles in \textit{alternating directions}, the last tiles accessed by one query become the first tiles needed by the next, enabling immediate L2 cache reuse.

\paragraph{Contributions.} We make the following contributions:
\begin{enumerate}
    \item We provide \textbf{empirical analysis} of L1/L2 cache behavior in FMHA, demonstrating that L2 access is deterministic and modelable with high accuracy.
    \item We characterize the \textbf{L2 capacity miss problem}, showing that misses emerge at sequence lengths well below theoretical L2 capacity limits.
    \item We introduce the \textbf{sawtooth access pattern}, where consecutive groups of query blocks alternate between forward and reverse KV traversal.
    \item We propose \texttt{AlternateReductionLoopPass}, a compiler transformation for CuTile IR that automatically applies the sawtooth pattern.
    \item We evaluate across \textbf{five kernel variants}, multiple configurations (causal/non-causal, FP16/FP8), and two frameworks (CuTile and Triton).
\end{enumerate}

%% ============================================================================
%% SECTION 2: BACKGROUND
%% ============================================================================
\section{Background}
\label{sec:background}

\subsection{Flash Attention and Tiled Computation}

Standard scaled dot-product attention computes:
\begin{equation}
 \mathbf{O} = \text{softmax}\left(\frac{\mathbf{Q}\mathbf{K}^T}{\sqrt{d}}\right)\mathbf{V}
\end{equation}
where $\mathbf{Q}, \mathbf{K}, \mathbf{V} \in \mathbb{R}^{N \times d}$. Materializing the $N \times N$ attention matrix is prohibitive for long sequences. Flash Attention~\cite{FlashAttention} avoids this by tiling the computation: for each query tile $\mathbf{Q}_i$, key and value tiles $\{\mathbf{K}_j, \mathbf{V}_j\}$ are streamed through, with online softmax maintaining numerical stability.

\subsection{GPU Memory Hierarchy}

NVIDIA GPUs feature a multi-level memory hierarchy:
\begin{itemize}
    \item \textbf{HBM (Global Memory):} High bandwidth, high latency off-chip memory.
    \item \textbf{L2 Cache:} Shared across all SMs, automatically managed (50 MB on GB10).
    \item \textbf{L1/Shared Memory:} Per-SM on-chip memory, partitioned between hardware-managed L1 cache and explicitly managed shared memory.
\end{itemize}

In FMHA kernels, shared memory is used for the working tiles of Q, K, V, and intermediate accumulators. Traffic between shared memory and HBM flows through L2.

\subsection{Kernel Implementation Algorithm}

We use a \textbf{split-Q} dataflow where Query tiles remain resident in shared memory while Key and Value tiles are streamed. The computation follows the standard Flash Attention forward pass:

\begin{algorithm}[ht]
\caption{Split-Q Fused Multihead Attention with Square Tiling}
\begin{algorithmic}[1]
\State \textbf{Input:} $\mathbf{Q}, \mathbf{K}, \mathbf{V} \in \text{Global Memory}$
\State \textbf{Config:} Determine max square tile size $T \times T$ based on SRAM
    \ParFor{$i = 1$ to $T_r$} \Comment{Grid-stride loop over Q}
    \State Load $\mathbf{Q}_i$ into Shared Memory (Resident)
    \State Initialize $\mathbf{O}_i = \mathbf{0}, \ell_i = \mathbf{0}, m_i = -\infty$
    \For{$j = 1$ to $T_c$} \Comment{Stream K, V tiles}
        \State Load $\mathbf{K}_j, \mathbf{V}_j$ into separate Shared Memory buffers
        \State Compute $\mathbf{S}_{ij} = \mathbf{Q}_i \mathbf{K}_j^T$ (WMMA)
        \State Update Softmax stats $m_i, \ell_i$ (Online Softmax)
        \State Compute $\mathbf{P}_{ij} = \text{softmax}(\mathbf{S}_{ij} \cdot \text{scale}, m_i, \ell_i)$
        \State Compute $\mathbf{O}_{i} \leftarrow \mathbf{O}_{i} + \mathbf{P}_{ij} \mathbf{V}_j$ (WMMA)
    \EndFor
    \State Write $\mathbf{O}_i$ to Global Memory
\EndFor
\end{algorithmic}
\end{algorithm}

\subsection{CTA Scheduling and Work Distribution}

To manage occupancy and load balancing, we employ a \textbf{persistent CTA} pattern with round-robin tile assignment:

\begin{algorithm}[ht]
\caption{Persistent CTA Scheduling (Grid-Stride Loop)}
\begin{algorithmic}[1]
\State \textbf{Input:} Total Query Tiles $N_{tiles}$, Grid Size $G$
\State \textbf{Given:} GPU SM Count $N_{SM}$
\State $G \leftarrow \min(N_{tiles}, N_{SM})$ \Comment{One persistent CTA per SM}
\State $k \leftarrow \text{blockIdx.x}$
\While{$k < N_{tiles}$}
    \State Identify ($Batch, Head, TileIndex$) from linear index $k$
    \State Execute \textbf{Algorithm 1} for this Query tile
    \State $k \leftarrow k + G$ \Comment{Stride by total number of CTAs}
\EndWhile
\end{algorithmic}
\end{algorithm}

%% ============================================================================
%% SECTION 3: MOTIVATION - UNDERSTANDING L2 CACHE BEHAVIOR
%% ============================================================================
\section{Motivation: Understanding L2 Cache Behavior}
\label{sec:motivation}

Before proposing optimizations, we establish a quantitative understanding of L2 cache behavior in FMHA kernels through empirical studies.

\subsection{L1 Effect on L2 Sector Access}

On traditional CPU architectures, L1 functions as a filter for L2, complicating L2 access analysis. For GPU attention kernels with explicitly managed shared memory, however, we hypothesize minimal L1 filtering effect.

Although $Q$ tiles are resident in shared memory, at the scale of the outer loop they stream from global memory. $K$ and $V$ tiles have even shorter tenancy. Hence, we should observe negligible L1 filtering.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{plots/l1_l2_b1_h1_s32768_d64.png}
    \caption{L1/L2 Metrics for Sequence Length 32K. Parameters: Batch=1, Heads=1, Head Dim=64, Tile Size=80$\times$80.}
    \label{fig:l1-l2-32k}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{plots/l1_l2_b1_h1_s131072_d64.png}
    \caption{L1/L2 Metrics for Sequence Length 128K. Parameters: Batch=1, Heads=1, Head Dim=64, Tile Size=80$\times$80.}
    \label{fig:l1-l2-128k}
\end{figure}

Table~\ref{tab:l1-l2-counters} lists exact counter values for the fully saturated case (SM=48).

\begin{table}[h]
\centering
\caption{L1/L2 Cache Counters for SM=48}
\label{tab:l1-l2-counters}
\begin{tabular}{lrr}
\toprule
\textbf{Metric} & \textbf{32K Seq Len} & \textbf{128K Seq Len} \\
\midrule
L2 Sectors (Total) & 107,729,467 & 1,723,556,561 \\
L2 Sectors (from Tex) & 107,478,656 & 1,719,093,980 \\
L1 Sectors (Total) & 107,478,656 & 1,718,615,808 \\
L1 Hit Count & 65,440 & 262,080 \\
\bottomrule
\end{tabular}
\end{table}

Key observations:
\begin{enumerate}
    \item L1Tex hit count is tiny (hence visualized on a separate axis), confirming that streaming data bypasses L1 caching benefits.
    \item L1 miss (traffic from L1 to L2) is the main contributor to L2 traffic.
    \item This behavior is consistent across sequence lengths and SM counts.
\end{enumerate}

\subsection{L2 Sector Access Modeling}

Given that L2 access has deterministic properties, we establish formulas for L2 sector access. For single-batch single-head case:

\begin{itemize}
    \item $S$: Sequence Length, $C$: Sector Size, $E$: Element Size
    \item $T$: Tile Size, $D$: Head Dimension, $M$: Number of Sectors
\end{itemize}

Each tile consists of $TD$ elements ($\frac{TDE}{C}$ sectors). For $Q$ and $O$, each tile is accessed once: $2\frac{TDE}{C}\left\lfloor\frac{S}{T}\right\rfloor$ sectors. Without causal masking, $K$ and $V$ are accessed once per $Q$ tile: $2\frac{TDE}{C}\left\lfloor\frac{S}{T}\right\rfloor^2$ sectors.

On GB10 with FP16 ($C = 32$, $E = 2$, $D = 64$):
\begin{equation}
M \approx 8S\left(1 + \frac{S}{T}\right) \quad \text{(Non-Causal)}
\end{equation}
\begin{equation}
M \approx 8S\left(\frac{S}{2T} + \frac{1}{2}\right) \quad \text{(Causal)}
\end{equation}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\linewidth]{plots/seqlen_change_sm48_regular.png}
    \caption{L2 Sector Access vs Sequence Length (Non-Causal, $T=80$).}
    \label{fig:study2-regular}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\linewidth]{plots/seqlen_change_sm48_causal.png}
    \caption{L2 Sector Access vs Sequence Length (Causal, $T=80$).}
    \label{fig:study2-causal}
\end{figure}

Table~\ref{tab:mape-results} shows our model fits experimental data with less than 1\% error.

\begin{table}[h]
\centering
\caption{MAPE of Theoretical Model vs Experimental Data (SM=48)}
\label{tab:mape-results}
\begin{tabular}{lrr}
\toprule
\textbf{Metric} & \textbf{Non-Causal(\%)} & \textbf{Causal (\%)} \\
\midrule
L2 Sectors (Total) & 0.4527\% & 2.4941\% \\
L2 Sectors (from Tex) & 0.5389\% & 1.1286\% \\
\bottomrule
\end{tabular}
\end{table}

\subsection{L2 Capacity Miss Problem}
\label{sec:l2-capacity}

If L2 can hold all data, misses should equal cold misses: $4\frac{SDE}{C} = 16S$ for our configuration.

However, experimental results show divergence at $S \approx 80$K (KV size = 20 MiB), significantly below the 50 MiB L2 capacity. This discrepancy---the \textbf{L2 capacity miss problem}---motivates our optimization.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\linewidth]{plots/seqlen_miss_change_sm48.png}
    \caption{L2 Miss Count vs Sequence Length (SM=48). Dashed line: theoretical cold miss ($16S$).}
    \label{fig:study3-miss}
\end{figure}

The early divergence suggests that concurrent CTAs streaming through KV tiles evict each other's cache lines before reuse can occur.

%% ============================================================================
%% SECTION 4: THE SAWTOOTH ACCESS PATTERN
%% ============================================================================
\section{The Sawtooth Access Pattern}
\label{sec:sawtooth}

\subsection{Core Concept}

The sawtooth access pattern exploits \textbf{intra-CTA temporal locality} between consecutive query tiles. Within a single CTA processing multiple query tiles:
\begin{itemize}
    \item \textbf{Query tile $i$ (even)}: traverse KV tiles in \textit{forward} order ($j = 0, 1, \ldots, T_c-1$).
    \item \textbf{Query tile $i+1$ (odd)}: traverse KV tiles in \textit{reverse} order ($j = T_c-1, \ldots, 1, 0$).
\end{itemize}

This creates a simple alternating pattern:
\begin{verbatim}
Q0: KV0  KV1  KV2  ...  KVn-1  KVn
Q1: KVn  KVn-1  ...  KV2  KV1  KV0
Q2: KV0  KV1  KV2  ...  KVn-1  KVn
Q3: KVn  KVn-1  ...  KV2  KV1  KV0
    ...
\end{verbatim}

\subsection{Why It Works}

When a CTA finishes processing query tile $Q_i$ in forward order, the \textit{last} KV tiles accessed ($\mathbf{K}_n, \mathbf{V}_n$) are still warm in L2 cache. If the next query tile $Q_{i+1}$ starts from the \textit{beginning} (as in the default forward-only pattern), those cached tiles are wasted---evicted before reuse.

With sawtooth, $Q_{i+1}$ starts from the \textit{end}, immediately reusing the cache-warm tiles:
\begin{itemize}
    \item $Q_i$ finishes with $\mathbf{K}_n, \mathbf{V}_n$ in cache.
    \item $Q_{i+1}$ starts by accessing $\mathbf{K}_n, \mathbf{V}_n$---\textbf{cache hit}.
    \item As $Q_{i+1}$ proceeds backward, it loads earlier tiles.
    \item $Q_{i+1}$ finishes with $\mathbf{K}_0, \mathbf{V}_0$ in cache.
    \item $Q_{i+2}$ starts forward, reusing $\mathbf{K}_0, \mathbf{V}_0$---\textbf{cache hit}.
\end{itemize}

This simple reversal transforms half of the KV tile accesses from cold misses to cache hits at the boundary between consecutive query tiles.

\subsection{Tile Grouping}

For practical implementation, we group query tiles into chunks of size $X$ (tile factor). All tiles within a group use the same direction, and direction alternates between groups. This amortizes the index computation overhead while preserving the boundary reuse benefit. We use $X = 8$ empirically.

%% ============================================================================
%% SECTION 5: COMPILER-LEVEL OPTIMIZATION
%% ============================================================================
\section{Compiler-Level Optimization}
\label{sec:compiler}

We introduce \texttt{AlternateReductionLoopPass}, a compiler transformation within the CuTile IR framework that automatically injects the sawtooth access pattern into compatible kernels. This pass relieves programmers from manually implementing complex index arithmetic and loop restructuring, ensuring correctness and performance portability.

\subsection{Algorithm Overview}

\begin{algorithm}[ht]
\caption{Alternate Reduction Loop Transformation}
\label{alg:sawtooth-transform}
\begin{algorithmic}[1]
\Require Outer loop over query tiles, inner reduction loop over KV tiles
\Require Tile factor $X$
\State Wrap outer loop in a \textbf{tile loop} iterating over groups of $X$
\State Compute \texttt{isOdd} $\gets$ (tile index) $\mod 2 \neq 0$
\For{each query tile $i$ in tile group}
    \For{$\text{step} = 0$ to $T_c - 1$}
        \If{\texttt{isOdd}}
            \State $j \gets T_c - 1 - \text{step}$ \Comment{Reverse direction}
        \Else
            \State $j \gets \text{step}$ \Comment{Forward direction}
        \EndIf
        \State Load $\mathbf{K}_j, \mathbf{V}_j$ and compute MMA
    \EndFor
\EndFor
\end{algorithmic}
\end{algorithm}

\subsection{Pass Implementation}

The transformation operates in four distinct phases:

\begin{enumerate}
    \item \textbf{Pattern Detection and Safety Analysis:} The pass first analyzes the IR to identify the outermost loop structure. Crucially, it must verify that the inner loop performs an \textbf{associative reduction}. This is essential because altering the traversal order (alternating between forward and reverse) is only mathematically valid for associative operations (like summation in matrix multiplication) or operations where order does not affect the final result (like finding the maximum). If the reduction is not associative, reordering could lead to incorrect results, so the pass conservatively skips such loops.
    \item \textbf{Loop Tiling:} Once a valid loop is identified, the pass applies loop tiling to create the granularity needed for the sawtooth pattern. The original loop is split into an outer ``tile loop'' (iterating over groups of tiles) and an inner ``iteration loop'' (iterating within a group). This hierarchical structure allows us to control direction switching at the tile-group boundary.
    \item \textbf{Index Computation:} Within the tiled structure, the pass injects logic to determine the traversal direction. It computes an \texttt{isOdd} boolean based on the tile group index. A \texttt{SelectOp} is then inserted to choose between the standard index (for forward traversal) and a computed reverse index ($N - 1 - i$) based on the \texttt{isOdd} condition.
    \item \textbf{IR Cloning and Remapping:} Finally, the body of the original loop is cloned into the new structure. All references to the original induction variable are remapped to the new, direction-aware index \texttt{SelectOp}. This ensures that all memory loads and computations within the loop automatically adhere to the new access pattern without requiring changes to the core kernel logic.
\end{enumerate}

\subsection{Limitations}

\paragraph{Assumed Loop Structure.} The pass assumes a repetition loop inside the CTA. Non-tiled kernels require restructuring to \textbf{tiled-loop stride} first.

\paragraph{No Cross-Launch Optimization.} CuTile IR operates within a single kernel launch. The pass cannot coordinate across launches or modify launch geometry.

%% ============================================================================
%% SECTION 6: IMPLEMENTATION VARIANTS
%% ============================================================================
\section{Implementation Variants}
\label{sec:variants}

We evaluate five kernel variants:

\begin{enumerate}
    \item \textbf{Default}: Standard Flash Attention with persistent CTAs, forward KV traversal.
    \item \textbf{Tiled Loop Stride}: Two-level tiled loop ($X=8$), all forward.
    \item \textbf{Tiled Loop Stride + Sawtooth}: Tiled loop with alternating direction.
    \item \textbf{Fully Static Scheduled}: Fixed CTA-to-tile assignment, forward only.
    \item \textbf{Fully Static + Sawtooth}: Static scheduling with alternating traversal.
\end{enumerate}

\subsection{Baseline Kernel Details}

The baseline kernel implements specific memory optimizations:

\subsubsection{Dynamic Square Tiling}
Unlike the original Flash Attention paper which suggests asymmetric tiling ($B_c \ll B_r$), our implementation calculates the maximum feasible \textbf{square tile size} $T$ at runtime:
\begin{equation}
\text{Mem}_{\text{req}} \approx 4T^2 + 10dT \leq \text{SRAM}_{\text{capacity}}
\end{equation}

\subsubsection{Shared Memory Layout \& Reuse}
To minimize shared memory footprint, we employ explicit buffer reuse:
\begin{itemize}
    \item \textbf{Coexistence:} $\mathbf{Q}$, $\mathbf{K}$, $\mathbf{V}$ tiles reside in distinct buffers during $\mathbf{Q}\mathbf{K}^T$.
    \item \textbf{Buffer Reuse:} After softmax, $\mathbf{K}$ buffer is repurposed for $\mathbf{P}$.
\end{itemize}

%% ============================================================================
%% SECTION 7: EXPERIMENTAL SETUP
%% ============================================================================
\section{Experimental Setup}
\label{sec:setup}

\subsection{Hardware}

NVIDIA GB10 GPU (Blackwell): 48 SMs, 50 MB L2, 32-byte sector size.

\subsection{Frameworks}

All variants implemented in \textbf{CuTile} and \textbf{Triton}.

\subsection{Configurations}

\begin{itemize}
    \item \textbf{Attention Type:} Non-causal and Causal
    \item \textbf{Quantization:} FP16 and FP8 E4M3
\end{itemize}

\subsection{Profiling Methodology}

We employ NVIDIA Nsight Compute CLI (\texttt{ncu}) to capture hardware counters:
\begin{itemize}
    \item \texttt{lts\_\_t\_sector\_hit\_rate.pct}: L2 hit rate
    \item \texttt{lts\_\_t\_sectors.sum}: Total L2 sector accesses
    \item \texttt{lts\_\_t\_sectors\_srcunit\_tex\_lookup\_miss.sum}: L2 misses
    \item \textbf{Kernel Execution Time}: End-to-end wall-clock time
\end{itemize}

Warmup runs precede measurement; metrics are averaged over multiple iterations with outliers removed.

%% ============================================================================
%% SECTION 8: PRELIMINARY RESULTS (EXISTING DATA)
%% ============================================================================
\section{Preliminary Results: CuTile Validation}
\label{sec:preliminary}

We first validate the sawtooth pattern effectiveness using CuTile implementations before extending to comprehensive evaluation.

\subsection{Non-Causal Attention}

\begin{table}[h]
\centering
\caption{CuTile Non-Causal: L2 Misses \& Throughput (128K Sequence)}
\label{tab:study5-data}
\begin{tabular}{lrrrr}
\toprule
\textbf{Variant} & \textbf{L2 Misses} & \textbf{L2 Misses} & \textbf{TFlops} & \textbf{TFlops} \\
 & \textbf{(Regular)} & \textbf{(Sawtooth)} & \textbf{(Regular)} & \textbf{(Sawtooth)} \\
\midrule
Fully Static & 372,244,480 & 122,117,820 & 61.58 & 69.34 \\
Tiled Loop & 369,644,856 & 127,651,952 & 60.74 & 69.24 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\linewidth]{plots/cutile_study5_misses.png}
    \caption{CuTile Non-Causal: L2 Miss Comparison}
    \label{fig:study5-misses}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\linewidth]{plots/cutile_study5_throughput.png}
    \caption{CuTile Non-Causal: Throughput Comparison}
    \label{fig:study5-throughput}
\end{figure}

The sawtooth pattern reduces L2 misses by approximately \textbf{3$\times$} and improves throughput by \textbf{12--14\%} for non-causal attention.

\subsection{Causal Attention}

\begin{table}[h]
\centering
\caption{CuTile Causal: L2 Misses \& Throughput (128K Sequence)}
\label{tab:study6-data}
\begin{tabular}{lrrrr}
\toprule
\textbf{Variant} & \textbf{L2 Misses} & \textbf{L2 Misses} & \textbf{TFlops} & \textbf{TFlops} \\
 & \textbf{(Regular)} & \textbf{(Sawtooth)} & \textbf{(Regular)} & \textbf{(Sawtooth)} \\
\midrule
Fully Static & 629,425,276 & 95,344,684 & 32.21 & 59.89 \\
Tiled Loop & 350,626,172 & 162,876,760 & 41.05 & 66.11 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\linewidth]{plots/cutile_study6_misses.png}
    \caption{CuTile Causal: L2 Miss Comparison}
    \label{fig:study6-misses}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\linewidth]{plots/cutile_study6_throughput.png}
    \caption{CuTile Causal: Throughput Comparison}
    \label{fig:study6-throughput}
\end{figure}

For causal attention, fully static with sawtooth achieves \textbf{6.6$\times$} L2 miss reduction and \textbf{1.86$\times$} throughput improvement. Tiled loop with sawtooth shows \textbf{2.2$\times$} miss reduction and \textbf{1.6$\times$} throughput gain.

%% ============================================================================
%% SECTION 9: COMPREHENSIVE RESULTS
%% ============================================================================
\section{Comprehensive Results}
\label{sec:results}

We now present full results across all variants, frameworks, and configurations.

\subsection{CuTile Results}

\subsubsection{FP16 Non-Causal}

\begin{table}[h]
\centering
\caption{CuTile FP16 Non-Causal Results}
\label{tab:cutile-fp16-noncausal}
\begin{tabular}{lrr}
\toprule
\textbf{Variant} & \textbf{L2 Misses} & \textbf{TFlops} \\
\midrule
Default & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Tiled Loop Stride & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Tiled + Sawtooth & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Fully Static & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Fully Static + Sawtooth & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[ht]
    \centering
    \textcolor{red}{[TODO: Bar chart for CuTile FP16 Non-Causal]}
    \caption{CuTile FP16 Non-Causal: L2 Misses vs Throughput}
    \label{fig:cutile-fp16-noncausal}
\end{figure}

\subsubsection{FP16 Causal}

\begin{table}[h]
\centering
\caption{CuTile FP16 Causal Results}
\label{tab:cutile-fp16-causal}
\begin{tabular}{lrr}
\toprule
\textbf{Variant} & \textbf{L2 Misses} & \textbf{TFlops} \\
\midrule
Default & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Tiled Loop Stride & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Tiled + Sawtooth & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Fully Static & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Fully Static + Sawtooth & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[ht]
    \centering
    \textcolor{red}{[TODO: Bar chart for CuTile FP16 Causal]}
    \caption{CuTile FP16 Causal: L2 Misses vs Throughput}
    \label{fig:cutile-fp16-causal}
\end{figure}

\subsubsection{FP8 Non-Causal}

\begin{table}[h]
\centering
\caption{CuTile FP8 Non-Causal Results}
\label{tab:cutile-fp8-noncausal}
\begin{tabular}{lrr}
\toprule
\textbf{Variant} & \textbf{L2 Misses} & \textbf{TFlops} \\
\midrule
Default & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Tiled Loop Stride & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Tiled + Sawtooth & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Fully Static & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Fully Static + Sawtooth & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[ht]
    \centering
    \textcolor{red}{[TODO: Bar chart for CuTile FP8 Non-Causal]}
    \caption{CuTile FP8 Non-Causal: L2 Misses vs Throughput}
    \label{fig:cutile-fp8-noncausal}
\end{figure}

\subsubsection{FP8 Causal}

\begin{table}[h]
\centering
\caption{CuTile FP8 Causal Results}
\label{tab:cutile-fp8-causal}
\begin{tabular}{lrr}
\toprule
\textbf{Variant} & \textbf{L2 Misses} & \textbf{TFlops} \\
\midrule
Default & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Tiled Loop Stride & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Tiled + Sawtooth & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Fully Static & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Fully Static + Sawtooth & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[ht]
    \centering
    \textcolor{red}{[TODO: Bar chart for CuTile FP8 Causal]}
    \caption{CuTile FP8 Causal: L2 Misses vs Throughput}
    \label{fig:cutile-fp8-causal}
\end{figure}

\subsection{Triton Results}

\subsubsection{FP16 Non-Causal}

\begin{table}[h]
\centering
\caption{Triton FP16 Non-Causal Results}
\label{tab:triton-fp16-noncausal}
\begin{tabular}{lrr}
\toprule
\textbf{Variant} & \textbf{L2 Misses} & \textbf{TFlops} \\
\midrule
Default & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Tiled Loop Stride & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Tiled + Sawtooth & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Fully Static & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Fully Static + Sawtooth & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[ht]
    \centering
    \textcolor{red}{[TODO: Bar chart for Triton FP16 Non-Causal]}
    \caption{Triton FP16 Non-Causal: L2 Misses vs Throughput}
    \label{fig:triton-fp16-noncausal}
\end{figure}

\subsubsection{FP16 Causal}

\begin{table}[h]
\centering
\caption{Triton FP16 Causal Results}
\label{tab:triton-fp16-causal}
\begin{tabular}{lrr}
\toprule
\textbf{Variant} & \textbf{L2 Misses} & \textbf{TFlops} \\
\midrule
Default & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Tiled Loop Stride & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Tiled + Sawtooth & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Fully Static & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Fully Static + Sawtooth & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[ht]
    \centering
    \textcolor{red}{[TODO: Bar chart for Triton FP16 Causal]}
    \caption{Triton FP16 Causal: L2 Misses vs Throughput}
    \label{fig:triton-fp16-causal}
\end{figure}

\subsubsection{FP8 Non-Causal}

\begin{table}[h]
\centering
\caption{Triton FP8 Non-Causal Results}
\label{tab:triton-fp8-noncausal}
\begin{tabular}{lrr}
\toprule
\textbf{Variant} & \textbf{L2 Misses} & \textbf{TFlops} \\
\midrule
Default & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Tiled Loop Stride & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Tiled + Sawtooth & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Fully Static & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Fully Static + Sawtooth & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[ht]
    \centering
    \textcolor{red}{[TODO: Bar chart for Triton FP8 Non-Causal]}
    \caption{Triton FP8 Non-Causal: L2 Misses vs Throughput}
    \label{fig:triton-fp8-noncausal}
\end{figure}

\subsubsection{FP8 Causal}

\begin{table}[h]
\centering
\caption{Triton FP8 Causal Results}
\label{tab:triton-fp8-causal}
\begin{tabular}{lrr}
\toprule
\textbf{Variant} & \textbf{L2 Misses} & \textbf{TFlops} \\
\midrule
Default & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Tiled Loop Stride & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Tiled + Sawtooth & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Fully Static & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
Fully Static + Sawtooth & \textcolor{red}{TODO} & \textcolor{red}{TODO} \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[ht]
    \centering
    \textcolor{red}{[TODO: Bar chart for Triton FP8 Causal]}
    \caption{Triton FP8 Causal: L2 Misses vs Throughput}
    \label{fig:triton-fp8-causal}
\end{figure}

%% ============================================================================
%% SECTION 10: DISCUSSION
%% ============================================================================
\section{Discussion}
\label{sec:discussion}

\subsection{Why Sawtooth Works}

The sawtooth pattern exploits temporal locality within a CTA's sequential processing of query tiles:
\begin{enumerate}
    \item \textbf{Cache line reuse at boundaries:} When $Q_i$ finishes, its last-accessed KV tiles remain in L2. By starting $Q_{i+1}$ from the opposite end, these tiles are immediately reused.
    \item \textbf{Reduced cold misses:} At each query tile transition, approximately half the KV tiles are cache hits instead of misses.
    \item \textbf{Works with L2's LRU-like policy:} Recently accessed tiles stay in cache; sawtooth ensures the ``recent'' tiles are exactly what's needed next.
\end{enumerate}

\subsection{Causal vs Non-Causal}

Causal masking creates asymmetric access. Early queries have shorter reductions, limiting sharing. Later queries benefit maximally. The preliminary results show causal attention benefits even more from sawtooth due to the higher baseline miss rate.

\subsection{Validation of Motivation}

The L2 capacity miss problem identified in Section~\ref{sec:l2-capacity} is directly addressed by sawtooth: by extending cache line lifetime at group boundaries, we reduce the effective concurrent working set and push the divergence point to higher sequence lengths.

\textcolor{red}{[TODO: Add specific comparison observations after data collection]}

%% ============================================================================
%% SECTION 11: RELATED WORK
%% ============================================================================
\section{Related Work}
\label{sec:related}

\subsection{Attention Optimization}

Flash Attention~\cite{FlashAttention} introduced IO-aware tiled computation for attention, reducing HBM$\leftrightarrow$SRAM traffic from $O(N^2)$ to $O(N)$. Flash Attention 2~\cite{FlashAttention2} improved parallelism and work partitioning. These works focus on the HBM-SRAM interface; our sawtooth pattern addresses the complementary L2 cache efficiency problem.

\subsection{GPU Cache Optimization}

\paragraph{Cache-Conscious Wavefront Scheduling.} Rogers et al.~\cite{10.1109/MICRO.2012.16} proposed CCWS, an adaptive hardware mechanism that detects intra-wavefront locality and reduces the number of actively issuing threads to avoid L1 thrashing. While CCWS targets L1, our software-based approach targets L2 without hardware modification.

\paragraph{CTA Scheduling for Locality.} Lee et al.~\cite{6835937} proposed alternative thread block scheduling to improve GPGPU resource utilization. Li et al.~\cite{10.1145/3037697.3037709} introduced Locality-Aware CTA Clustering, reshaping default CTA scheduling to group CTAs with potential reuse on the same SM. These works modify CTA-to-SM assignment; our sawtooth pattern modifies memory access order \textit{within} CTAs.

\paragraph{GPU Microbenchmarking.} Jia et al.~\cite{GPUCacheOpt} dissected GPU memory hierarchy through microbenchmarking, revealing cache behavior patterns. Our work builds on such understanding to design access patterns that exploit L2 caching.

\subsection{Loop Transformations}

Classical loop tiling and interchange~\cite{LoopTiling} optimize cache behavior in single-threaded contexts. Our \texttt{AlternateReductionLoopPass} adapts these principles for multi-CTA GPU execution, where the challenge is coordinating access patterns across concurrent thread blocks sharing L2.

%% ============================================================================
%% SECTION 12: CONCLUSION
%% ============================================================================
\section{Conclusion}
\label{sec:conclusion}

We presented the \textbf{sawtooth access pattern}, reducing L2 cache misses in FMHA kernels by alternating KV traversal direction. Through empirical analysis, we established that L2 behavior is deterministic and identified the capacity miss problem that motivates our optimization.

Preliminary CuTile results demonstrate 3--6$\times$ L2 miss reduction and up to 1.86$\times$ throughput improvement. Our \texttt{AlternateReductionLoopPass} enables automatic application in CuTile IR.

\paragraph{Future Work.} Extend to multi-launch scenarios, adaptive tile factor selection, and other streaming GPU workloads.

%%
%% Bibliography
%%
\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\end{document}
